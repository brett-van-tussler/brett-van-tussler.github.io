{
  "similarity-network-fusion-(snf)": {
    "id": "similarity-network-fusion-(snf)",
    "title": "Similarity Network Fusion (SNF)",
    "emoji": "üîó",
    "definition": "‚Ä¢ Definition: A computational method that integrates multiple data types to create a unified patient similarity network, enabling more comprehensive analysis than single-data approaches.\n\n‚Ä¢ Algorithm principles:\n  - Constructs similarity networks for each data type separately\n  - Iteratively updates each network by fusing information from other networks\n  - Converges to a single integrated network that captures complementary information across data types\n  - Uses spectral clustering for patient stratification and subtype identification\n\n‚Ä¢ Applications in multi-omics integration:\n  - Cancer subtyping: Identifying disease subtypes by integrating genomic, transcriptomic, and clinical data\n  - Biomarker discovery: Finding robust biomarkers across multiple data platforms\n  - Patient stratification: Grouping patients with similar molecular profiles across different data types\n  - Drug response prediction: Integrating molecular and pharmacological data to predict treatment outcomes\n\n‚Ä¢ Advantages over single-data analysis:\n  - Increased statistical power through data integration\n  - Robustness to noise in individual data types\n  - Ability to capture complementary information across heterogeneous data\n  - Improved prediction accuracy for clinical outcomes\n\n‚Ä¢ Implementation considerations:\n  - Parameter selection (number of neighbors, fusion iterations)\n  - Data normalization across different platforms\n  - Computational efficiency for large datasets\n  - Visualization of integrated networks",
    "tags": [],
    "linkedTerms": []
  },
  "chain-rule": {
    "id": "chain-rule",
    "title": "Chain Rule",
    "emoji": "üîó",
    "definition": "A fundamental rule in calculus for computing the derivative of composite functions. If you have a composite function f(g(x)), the chain rule states that the derivative is f'(g(x)) √ó g'(x). This rule is essential in backpropagation algorithms used in a neural network.",
    "tags": ["machine-learning", "mathematics"],
    "linkedTerms": ["derivative", "backpropagation", "neural-network"]
  },
  "derivative": {
    "id": "derivative",
    "title": "Derivative",
    "emoji": "üìà",
    "definition": "A measure of how a function changes as its input changes. Formally, the derivative of a function f at point x is the limit of the ratio of the change in f to the change in x as the change in x approaches zero. The gradient descent algorithm relies heavily on computing derivatives.",
    "tags": ["mathematics", "machine-learning"],
    "linkedTerms": ["gradient-descent", "chain-rule"]
  },
  "backpropagation": {
    "id": "backpropagation",
    "title": "Backpropagation",
    "emoji": "üîÑ",
    "definition": "An algorithm used to train neural networks by computing gradients of the loss function with respect to the network's weights. It works by applying the chain rule to compute these gradients efficiently, propagating errors backward through the network.",
    "tags": ["machine-learning"],
    "linkedTerms": ["chain-rule", "gradient-descent", "neural-network"]
  },
  "gradient-descent": {
    "id": "gradient-descent",
    "title": "Gradient Descent",
    "emoji": "‚¨áÔ∏è",
    "definition": "An optimization algorithm used to minimize a function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. It uses derivatives to determine the direction and magnitude of each step.",
    "tags": ["machine-learning", "mathematics"],
    "linkedTerms": ["derivative", "backpropagation"]
  },
  "neural-network": {
    "id": "neural-network",
    "title": "Neural Network",
    "emoji": "üß†",
    "definition": "A computational model inspired by biological neural networks. It consists of interconnected nodes (neurons) organized in layers, where each connection has an associated weight that is adjusted during training using algorithms like backpropagation.",
    "tags": ["machine-learning"],
    "linkedTerms": ["backpropagation", "gradient-descent"]
  },
  "dna-sequencing": {
    "id": "dna-sequencing",
    "title": "DNA Sequencing",
    "emoji": "üß¨",
    "definition": "The process of determining the precise order of nucleotides within a DNA molecule. Modern sequencing often uses machine learning algorithms for base calling and quality assessment.",
    "tags": ["bioinformatics"],
    "linkedTerms": ["base-calling"]
  },
  "base-calling": {
    "id": "base-calling",
    "title": "Base Calling",
    "emoji": "üìû",
    "definition": "The process of determining the identity of nucleotide bases from raw sequencing data. Modern base calling algorithms often employ neural networks and other machine learning techniques to improve accuracy.",
    "tags": ["bioinformatics", "machine-learning"],
    "linkedTerms": ["dna-sequencing", "neural-network"]
  }
}